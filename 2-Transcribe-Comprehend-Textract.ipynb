{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS AI Services APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install AWS Python SDK client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade boto3\n",
    "!python -m pip install amazon-textract-response-parser --upgrade\n",
    "!python -m pip install amazon-textract-prettyprinter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages import\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#Textract Libraries for parsing results\n",
    "from trp import Document\n",
    "from textractprettyprinter.t_pretty_print import Pretty_Print_Table_Format, Textract_Pretty_Print, get_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimedia Transcription Exercise\n",
    "\n",
    "## Amazon Transcribe client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe = boto3.client('transcribe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify an audio file to transcribe and generate a UUID as a job name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_uri = \"s3://m2c-gps304-workshop-us-east-1/lab1-assets/AWS_Podcast_Episode_317_demo.mp3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the audio file transcription job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = str(uuid.uuid4())\n",
    "\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName = job_name,\n",
    "    Media = {'MediaFileUri': media_uri},\n",
    "    MediaFormat='mp3',\n",
    "    LanguageCode='en-US'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the transcription job progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        print(f\"Transcription Status: {status['TranscriptionJob']['TranscriptionJobStatus']}\")\n",
    "        break\n",
    "    print(f\"Transcription Status: {status['TranscriptionJob']['TranscriptionJobStatus']}\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the audio transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_json = json.loads(urlopen(status['TranscriptionJob']['Transcript']['TranscriptFileUri']).read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_transcription = transcription_json['results']['transcripts'][0]['transcript']\n",
    "print(f\"{original_transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the original transcription with a custom vocabulary\n",
    "\n",
    "The description to create a table-based custom vocabulary is described in the [Transcribe documentation](https://docs.aws.amazon.com/transcribe/latest/dg/how-vocabulary.html)\n",
    "\n",
    "To make things simpler, we already prepared a tab-separated file to create a table-based custom vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_name = str(uuid.uuid4())\n",
    "response = transcribe.create_vocabulary(\n",
    "    VocabularyName= vocabulary_name,\n",
    "    LanguageCode='en-US',\n",
    "    VocabularyFileUri='s3://m2c-gps304-workshop-us-east-1/lab1-assets/custom_vocab.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the custom vocabulary  creation job progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    response = transcribe.get_vocabulary(\n",
    "        VocabularyName=vocabulary_name\n",
    "    )    \n",
    "    status = response['VocabularyState']\n",
    "    if status in ['READY', 'FAILED']:\n",
    "        print(response)\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe the original  file using the custom vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = str(uuid.uuid4())\n",
    "\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName = job_name,\n",
    "    Media = {'MediaFileUri': media_uri},\n",
    "    MediaFormat='mp3',\n",
    "    LanguageCode='en-US',\n",
    "    Settings={\n",
    "        'VocabularyName': vocabulary_name\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        print(f\"Transcription Status: {status['TranscriptionJob']['TranscriptionJobStatus']}\")\n",
    "        break\n",
    "    print(f\"Transcription Status: {status['TranscriptionJob']['TranscriptionJobStatus']}\")\n",
    "    time.sleep(15)\n",
    "    \n",
    "transcription = json.loads(urlopen(status['TranscriptionJob']['Transcript']['TranscriptFileUri']).read().decode('utf-8'))\n",
    "new_transcription = transcription['results']['transcripts'][0]['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the enhanced transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{new_transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP) with Amazon Comprehend Exercise\n",
    "\n",
    "## Create an Amazon Comprehend client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehendResponse = comprehend.detect_entities(Text=new_transcription, LanguageCode='en')\n",
    "\n",
    "for i in range(len(comprehendResponse[\"Entities\"])):\n",
    "    entity = comprehendResponse[\"Entities\"][i]\n",
    "    print(f\"Entity Type:{entity['Type']} Entity Text:{entity['Text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehendResponse = comprehend.detect_sentiment(Text=new_transcription, LanguageCode='en')\n",
    "comprehendResponse['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key phrases detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehendResponse = comprehend.detect_key_phrases(Text=new_transcription, LanguageCode='en')\n",
    "\n",
    "for i in range(len(comprehendResponse[\"KeyPhrases\"])):\n",
    "    key_phrase = comprehendResponse[\"KeyPhrases\"][i]\n",
    "    print(f\"Key Phrase:{key_phrase['Text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Document Processing (IDP) with Amazon Textract Exercise\n",
    "\n",
    "## Document to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Document to Analyze](sampledoc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Amazon Textract client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textract = boto3.client('textract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the document file bytes as a bytearray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentName = \"sampledoc.png\"\n",
    "with open(documentName, 'rb') as document:\n",
    "    imageBytes = bytearray(document.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Amazon Textract AnalyzeDocument sychronous API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Amazon Textract\n",
    "response = textract.analyze_document(Document={'Bytes': imageBytes},FeatureTypes=[\"FORMS\", \"TABLES\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Textract pretty printer tool to show the form values detected as key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty_printed_string = get_string(textract_json=response, output_type=[Textract_Pretty_Print.FORMS], table_format=Pretty_Print_Table_Format.fancy_grid)\n",
    "print(pretty_printed_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Textract pretty printer tool to show the tables detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_printed_string = get_string(textract_json=response, output_type=[Textract_Pretty_Print.TABLES], table_format=Pretty_Print_Table_Format.fancy_grid)\n",
    "print(pretty_printed_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Textract pretty printer tool to show the text detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty_printed_string = get_string(textract_json=response, output_type=[Textract_Pretty_Print.LINES], table_format=Pretty_Print_Table_Format.fancy_grid)\n",
    "print(pretty_printed_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Comprehend entities detection on document text detected by Amazon Textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehendResponse = comprehend.detect_entities(Text=pretty_printed_string, LanguageCode='en')\n",
    "\n",
    "for i in range(len(comprehendResponse[\"Entities\"])):\n",
    "    entity = comprehendResponse[\"Entities\"][i]\n",
    "    print(f\"Entity Type:{entity['Type']} Entity Text:{entity['Text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
